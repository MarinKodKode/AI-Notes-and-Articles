{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO6CTCbYxVr61X4O1yH2hQu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ea7039d9f85047f9b3a9e6913398f3d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b26dae86d50646faaf7cd4260ccc7883",
              "IPY_MODEL_d3d4180623bb44c68657fa636e292242",
              "IPY_MODEL_bf87191df6ef4c05bc60eb0a3845c0c7"
            ],
            "layout": "IPY_MODEL_249d730da7ab4c50819a9ee716dc0b63"
          }
        },
        "b26dae86d50646faaf7cd4260ccc7883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0636033ca62d4dd0b446e594a74b291f",
            "placeholder": "​",
            "style": "IPY_MODEL_2f658275719f4269a35fb898d5949f96",
            "value": "Map: 100%"
          }
        },
        "d3d4180623bb44c68657fa636e292242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52a2035637dd4ea595340842d4efae46",
            "max": 872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e434b2c5e384060bcdf22bbbf1b2bc8",
            "value": 872
          }
        },
        "bf87191df6ef4c05bc60eb0a3845c0c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abfede448d4449c8bda9fe618540d12a",
            "placeholder": "​",
            "style": "IPY_MODEL_209a59e1673b4268ad3788495be1645b",
            "value": " 872/872 [00:00&lt;00:00, 3710.85 examples/s]"
          }
        },
        "249d730da7ab4c50819a9ee716dc0b63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0636033ca62d4dd0b446e594a74b291f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f658275719f4269a35fb898d5949f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52a2035637dd4ea595340842d4efae46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e434b2c5e384060bcdf22bbbf1b2bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "abfede448d4449c8bda9fe618540d12a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "209a59e1673b4268ad3788495be1645b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarinKodKode/MasterDegree-AI/blob/main/TSA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ebmtoic_Xtdb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sentiment Analysis through Fine-Tuning Transformer Models"
      ],
      "metadata": {
        "id": "Z4Tk-zIwfEzz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Texas University\n",
        "*  Head Engineer. Manuel Alejandro Hernandez Marin\n",
        "\n"
      ],
      "metadata": {
        "id": "rYqEgCnlfI4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        " Sentiment analysis is one of the fundamental tasks within Natural Language Processing (NLP), as it allows the emotional polarity of written texts to be identified and has direct applications in areas such as opinion analysis, social media, customer service, and recommendation systems. Traditionally, this task has been approached using methods based on manual features and classical machine learning models.\n",
        "\n",
        "However, in recent years, models based on Transformer architectures have demonstrated significantly superior performance by incorporating deep contextual representations and attention mechanisms. These models, being pre-trained on large volumes of text, can be efficiently adapted to specific tasks through fine-tuning processes.\n",
        "\n",
        "In this work, a sentiment analysis model is implemented using the HuggingFace Transformers library, applying fine-tuning on a pre-trained DistilBERT model and using the SST-2 dataset from the GLUE benchmark. This approach allows us to evaluate the impact of modern NLP techniques and contrast them with traditional sentiment analysis approaches."
      ],
      "metadata": {
        "id": "4HohGUeGeu6m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Justification\n",
        "\n",
        "The approach proposed in the original group task of the activity provides an adequate introduction to sentiment analysis and is useful as a first conceptual approach. However, this approach is based on techniques and tools that have been largely superseded by more recent models, especially in deep semantic understanding tasks.\n",
        "\n",
        "In contrast, the use of fine-tuned Transformer models allows for the use of pre-trained linguistic representations, reducing the need for manual feature engineering and significantly improving model performance. DistilBERT, in particular, offers an adequate balance between accuracy and computational efficiency, making it a practical choice for academic environments.\n",
        "\n",
        "Furthermore, implementation with HuggingFace Transformers facilitates experiment reproducibility, access to standardized datasets, and evaluation using widely accepted metrics such as accuracy and F1-score. For these reasons, this methodology was chosen with the aim of applying an up-to-date approach, aligned with current industry practices and research in Natural Language Processing.\n",
        "\n",
        "The dataset used has an English-based lexicon, due to the robustness that the model offers compared to other languages, such as Spanish."
      ],
      "metadata": {
        "id": "GOUye6Ule43V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "UfXqnjDWWldN"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Library installation\n",
        "# Need HuggingFace dataset\n",
        "\n",
        "!pip install -q transformers datasets evaluate accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# load dataset (SST-2)\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"glue\", \"sst2\")\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xOFdXP12W2I3",
        "outputId": "350d07af-75f1-4ab1-c689-eedd78e5961c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence', 'label', 'idx'],\n",
              "        num_rows: 67349\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence', 'label', 'idx'],\n",
              "        num_rows: 872\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence', 'label', 'idx'],\n",
              "        num_rows: 1821\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WKoBw_xuWqLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load tokenizer\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
      ],
      "metadata": {
        "id": "HxzrZejQXZoL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tokenization function\n",
        "\n",
        "def tokenize_function(batch) :\n",
        "  return tokenizer(\n",
        "      batch[\"sentence\"],\n",
        "      padding=\"max_length\",\n",
        "      truncation=True\n",
        "  )"
      ],
      "metadata": {
        "id": "6_HhmzZOXnad"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply function to dataset\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292,
          "referenced_widgets": [
            "ea7039d9f85047f9b3a9e6913398f3d3",
            "b26dae86d50646faaf7cd4260ccc7883",
            "d3d4180623bb44c68657fa636e292242",
            "bf87191df6ef4c05bc60eb0a3845c0c7",
            "249d730da7ab4c50819a9ee716dc0b63",
            "0636033ca62d4dd0b446e594a74b291f",
            "2f658275719f4269a35fb898d5949f96",
            "52a2035637dd4ea595340842d4efae46",
            "9e434b2c5e384060bcdf22bbbf1b2bc8",
            "abfede448d4449c8bda9fe618540d12a",
            "209a59e1673b4268ad3788495be1645b"
          ]
        },
        "id": "-r9WgLi-X8C7",
        "outputId": "27310422-6cc6-4b49-e5ca-6ae8c48297ef"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea7039d9f85047f9b3a9e6913398f3d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 67349\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 872\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 1821\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load model\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\",\n",
        "    num_labels=2\n",
        ")\n"
      ],
      "metadata": {
        "id": "ajuSUta0YmW3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "89737340-712c-4a4e-de3f-fcc54ed857e7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set metrics and evaluating function\n",
        "\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "f1=evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred) :\n",
        "  logits, labels = eval_pred\n",
        "  predictions = np.argmax(logits, axis=1)\n",
        "  return {\n",
        "      \"accuracy\" : accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"],\n",
        "      \"f1\" : f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
        "  }"
      ],
      "metadata": {
        "id": "geLsvod4ZSZa"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define training params\n",
        "\n",
        "from transformers import TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    report_to=\"none\"\n",
        ")"
      ],
      "metadata": {
        "id": "Zl5AV7a5cqGG"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following parameters are defined with the respective considerations:\n",
        "\n",
        "\n",
        "* **low learning rate**: ensuring stable fine-tuning\n",
        "* **2 epochs**: prevents overfitting\n",
        "* **batch size 16**: standard in BERT.\n",
        "\n"
      ],
      "metadata": {
        "id": "eOUU5dYgd4DZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run trainer\n",
        "\n",
        "from transformers import Trainer\n",
        "trainer = Trainer (\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Execute trainer\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "1E-imFq6dzoq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "4202cedf-b7e7-4f45-ac91-c86c44fb7098"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8420' max='8420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8420/8420 1:39:03, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.183200</td>\n",
              "      <td>0.316708</td>\n",
              "      <td>0.904817</td>\n",
              "      <td>0.905575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.128000</td>\n",
              "      <td>0.354539</td>\n",
              "      <td>0.904817</td>\n",
              "      <td>0.908287</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=8420, training_loss=0.17690961751688689, metrics={'train_runtime': 5944.3665, 'train_samples_per_second': 22.66, 'train_steps_per_second': 1.416, 'total_flos': 1.7843093664165888e+16, 'train_loss': 0.17690961751688689, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"./sentiment_model\")\n",
        "tokenizer.save_pretrained(\"./sentiment_model\")"
      ],
      "metadata": {
        "id": "_ZGqkUI6uoSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference test with real context\n",
        "\n",
        "import torch\n",
        "\n",
        "def predict_sentiment(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
        "    return \"POSITIVE\" if prediction == 1 else \"NEGATIVE\"\n",
        "\n",
        "examples = [\n",
        "    \"This movie was absolutely amazing, I loved every minute of it.\",\n",
        "    \"The film was boring and a complete waste of time.\",\n",
        "    \"The acting was okay, but the story was very weak.\",\n",
        "    \"I would definitely recommend this movie to my friends.\",\n",
        "    \"This was the worst movie I have seen in years.\"\n",
        "]\n",
        "\n",
        "for text in examples:\n",
        "    print(f\"{text} -> {predict_sentiment(text)}\")"
      ],
      "metadata": {
        "id": "Q4e5H2R-c7XL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "851296e8-d978-4ffb-d670-0641b5dbfed4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This movie was absolutely amazing, I loved every minute of it. -> POSITIVE\n",
            "The film was boring and a complete waste of time. -> NEGATIVE\n",
            "The acting was okay, but the story was very weak. -> NEGATIVE\n",
            "I would definitely recommend this movie to my friends. -> POSITIVE\n",
            "This was the worst movie I have seen in years. -> NEGATIVE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusions\n",
        "\n",
        "The fine-tuned DistilBERT model achieved strong performance on the SST-2 sentiment classification task, reaching an accuracy of approximately 90% and an F1-score above 0.90 on the validation set. These results demonstrate the effectiveness of transformer-based models for sentiment analysis, even when using a relatively compact architecture such as DistilBERT.\n",
        "\n",
        "During training, a decrease in training loss was observed across epochs, indicating that the model successfully learned the underlying patterns in the data. A slight increase in validation loss in the second epoch suggests mild overfitting, highlighting the importance of monitoring validation metrics and applying early stopping when necessary.\n",
        "\n",
        "The use of GPU acceleration significantly reduced training time and enabled efficient experimentation. Overall, this project confirms that fine-tuning pre-trained transformer models is a powerful and practical approach for sentiment analysis tasks, providing high performance with manageable computational cost."
      ],
      "metadata": {
        "id": "xQqVX4SYWAiE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WMNto8dFuoD0"
      }
    }
  ]
}